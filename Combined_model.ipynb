{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "import tensorflow.metrics\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, shutil, random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing function for demographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: age was rounded in steps of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dem(train,test):\n",
    "\n",
    "\n",
    "    #replace missing age values by median\n",
    "    train['age'] = train['age'].fillna(train['age'].median())\n",
    "    test['age'] = test['age'].fillna(train['age'].median())\n",
    "    \n",
    "    # performin min-max scaling each continuous feature column to\n",
    "    # the range [0, 1]\n",
    "    cs = MinMaxScaler()\n",
    "    train[\"age\"] = cs.fit_transform(train[\"age\"].values.reshape(-1,1))\n",
    "    test[\"age\"] = cs.transform(test[\"age\"].values.reshape(-1,1))\n",
    " \n",
    "    train['sex'].replace(\"unknown\",train['sex'].value_counts().index[0], inplace=True)\n",
    "    train[\"sex\"] = np.where(train['sex']==\"female\",1,0)\n",
    "    \n",
    "    test['sex'].replace(\"unknown\",train['sex'].value_counts().index[0], inplace=True)\n",
    "    test[\"sex\"] = np.where(test['sex']==\"female\",1,0)\n",
    "    \n",
    "    # return the concatenated training and testing data\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load demographic data for all images (inkl. augmented images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnose = ['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']\n",
    "\n",
    "train_dir = \"/Users/leona/PythonWork/Github_Projects/Final_Pro/data/ISIC2018_Task3_Training_Input/train/\"\n",
    "validation_dir = \"/Users/leona/PythonWork/Github_Projects/Final_Pro/data/ISIC2018_Task3_Training_Input/validation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load main, train and test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_pickle(\"./meta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"./aug_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_pickle(\"./aug_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pr, validation_pr = preprocess_dem(train,validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit(train_pr.dx)\n",
    "\n",
    "def get_input(path):\n",
    "    img = load_img(path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) \n",
    "    return(img_array)\n",
    "\n",
    "def preprocess_input(img):\n",
    "    \"\"\" Same preprocessing function as mobilenets preprocess input\"\"\"\n",
    "    img /= 255.\n",
    "    img -= 0.5\n",
    "    img *= 2.\n",
    "    return img\n",
    "\n",
    "def multi_input_generator(df, batch_size, source_dir,shuffle=True):\n",
    "    \"\"\"Read images and metadata from dataframe. \n",
    "    Arguments: \n",
    "    - source_dir = either train or validation diectory\n",
    "    -> important: for test batches set shuffle=False and batch_size=1\"\"\"\n",
    "    \n",
    "    idx = 0\n",
    "\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            batch = df.sample(n=batch_size, replace=False)\n",
    "        else:\n",
    "            batch = df.loc[idx:(idx*batch_size), :] #attention:works only with batch_size=1\n",
    "\n",
    "        batch_input1 = []\n",
    "        batch_input2 = []\n",
    "        batch_output = [] \n",
    "          \n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for i in batch.index:\n",
    "            \n",
    "            full_path = source_dir + str(batch.loc[i].dx) + \"/\" + str(batch.loc[i].aug_id)\n",
    "            input1 = get_input(full_path)\n",
    "            input2 = [batch.loc[i].age, batch.loc[i].sex]\n",
    "            output = batch.loc[i].dx\n",
    "            \n",
    "            input_pre = preprocess_input(input1)\n",
    "            batch_input1 += [ input_pre ]\n",
    "            batch_input2 += [ input2 ]\n",
    "            batch_output += [ output ]\n",
    "        \n",
    "        # flatten the image list so that it looks like the tensorflow iterator\n",
    "        batch_input1 = [val for sublist in batch_input1 for val in sublist]\n",
    "        \n",
    "        # Return a tuple of ([input,input],output) to feed the network\n",
    "        batch_x1 = np.array(batch_input1)\n",
    "        batch_x2 = np.array(batch_input2, dtype=\"float32\")\n",
    "        batch_y = lb.transform(np.array(batch_output)).astype(\"float32\")\n",
    "        \n",
    "        yield[batch_x1, batch_x2], batch_y\n",
    "        idx += 1\n",
    "        \n",
    "        if idx >= len(df):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = multi_input_generator(train_pr,10,train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa,bb = next(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.78039217, -0.01960784,  0.09019613],\n",
       "          [ 0.7647059 , -0.05098039,  0.00392163],\n",
       "          [ 0.78039217, -0.01960784,  0.09019613],\n",
       "          ...,\n",
       "          [ 0.8039216 ,  0.05882359,  0.10588241],\n",
       "          [ 0.77254903,  0.02745104,  0.05882359],\n",
       "          [ 0.7882353 ,  0.02745104,  0.11372554]],\n",
       " \n",
       "         [[ 0.7647059 , -0.02745098,  0.03529418],\n",
       "          [ 0.75686276,  0.00392163,  0.09019613],\n",
       "          [ 0.7490196 , -0.01176471,  0.07450986],\n",
       "          ...,\n",
       "          [ 0.78039217,  0.05098045,  0.11372554],\n",
       "          [ 0.7647059 ,  0.03529418,  0.09803927],\n",
       "          [ 0.7647059 ,  0.0196079 ,  0.082353  ]],\n",
       " \n",
       "         [[ 0.77254903,  0.01176476,  0.09803927],\n",
       "          [ 0.7882353 ,  0.00392163,  0.09803927],\n",
       "          [ 0.77254903, -0.03529412, -0.00392157],\n",
       "          ...,\n",
       "          [ 0.8117647 ,  0.05098045,  0.13725495],\n",
       "          [ 0.75686276,  0.0196079 ,  0.14509809],\n",
       "          [ 0.81960785,  0.02745104,  0.15294123]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.64705884,  0.03529418, -0.05882353],\n",
       "          [ 0.6627451 ,  0.05098045, -0.02745098],\n",
       "          [ 0.62352943,  0.05098045, -0.06666666],\n",
       "          ...,\n",
       "          [ 0.70980394,  0.07450986,  0.12156868],\n",
       "          [ 0.7176471 ,  0.082353  ,  0.12941182],\n",
       "          [ 0.73333335,  0.09019613,  0.13725495]],\n",
       " \n",
       "         [[ 0.654902  ,  0.04313731, -0.05882353],\n",
       "          [ 0.64705884,  0.03529418, -0.06666666],\n",
       "          [ 0.64705884,  0.05098045, -0.05882353],\n",
       "          ...,\n",
       "          [ 0.70980394,  0.07450986,  0.06666672],\n",
       "          [ 0.6862745 ,  0.082353  ,  0.03529418],\n",
       "          [ 0.7176471 ,  0.09019613,  0.082353  ]],\n",
       " \n",
       "         [[ 0.6627451 ,  0.0196079 , -0.0745098 ],\n",
       "          [ 0.654902  ,  0.05882359, -0.04313725],\n",
       "          [ 0.6784314 ,  0.03529418, -0.05882353],\n",
       "          ...,\n",
       "          [ 0.67058825,  0.0196079 , -0.02745098],\n",
       "          [ 0.67058825,  0.04313731, -0.01176471],\n",
       "          [ 0.67058825,  0.05882359,  0.04313731]]]], dtype=float32),\n",
       " array([[0.47058824, 1.        ]], dtype=float32)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batches = multi_input_generator(validation_pr,10,validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = multi_input_generator(validation_pr,1, validation_dir,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 8912 # length of original not-augmented train data\n",
    "num_val_samples = 1103\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "image_size = 224\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 18:10:03.331333 4680467904 deprecation.py:506] From /Users/leona/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0818 18:10:03.332475 4680467904 deprecation.py:506] From /Users/leona/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0818 18:10:03.333572 4680467904 deprecation.py:506] From /Users/leona/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0818 18:10:03.338477 4680467904 deprecation.py:506] From /Users/leona/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "cnn = tensorflow.keras.models.load_model('combined_model_new.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_output = cnn.layers[-3].output # global average pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dem = tensorflow.keras.layers.Input(shape=(2,))\n",
    "x_dem = Dense(16, activation=\"relu\",name=\"dense_dem\")(input_dem)\n",
    "x_dem = Dropout(0.25, name=\"dropout_dem\")(x_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = layers.concatenate(inputs=[cnn_output,x_dem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(64, activation=\"relu\")(merge_layer)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "predictions = Dense(7, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_new = Model(inputs=[cnn.input, input_dem], outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile merged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to choose how many layers we actually want to be trained.\n",
    "\n",
    "# Here we are freezing the weights of all layers except the\n",
    "# last 15 layers in the new model.\n",
    "# The last 15 layers of the model will be trained.\n",
    "\n",
    "for layer in combined_model_new.layers[:-10]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Top3 Accuracy\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(Adam(lr=0.01), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy, top_3_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define class weights to account for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={\n",
    "    0: 1.0, # akiec\n",
    "    1: 1.0, # bcc\n",
    "    2: 1.0, # bkl\n",
    "    3: 1.0, # df\n",
    "    4: 3.0, # mel # Try to make the model more sensitive to Melanoma.\n",
    "    5: 1.0, # nv\n",
    "    6: 1.0, # vasc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "891/892 [============================>.] - ETA: 0s - loss: 0.9733 - categorical_accuracy: 0.7048 - top_3_accuracy: 0.9388\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.71712, saving model to combined_model_new.h5\n",
      "892/892 [==============================] - 586s 657ms/step - loss: 0.9735 - categorical_accuracy: 0.7046 - top_3_accuracy: 0.9389 - val_loss: 0.9670 - val_categorical_accuracy: 0.7171 - val_top_3_accuracy: 0.9261\n",
      "Epoch 2/30\n",
      "891/892 [============================>.] - ETA: 0s - loss: 0.8507 - categorical_accuracy: 0.7541 - top_3_accuracy: 0.9580\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.71712 to 0.77477, saving model to combined_model_new.h5\n",
      "892/892 [==============================] - 590s 662ms/step - loss: 0.8506 - categorical_accuracy: 0.7541 - top_3_accuracy: 0.9578 - val_loss: 0.7375 - val_categorical_accuracy: 0.7748 - val_top_3_accuracy: 0.9315\n",
      "Epoch 3/30\n",
      "891/892 [============================>.] - ETA: 0s - loss: 0.8216 - categorical_accuracy: 0.7563 - top_3_accuracy: 0.9632\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.77477\n",
      "892/892 [==============================] - 546s 612ms/step - loss: 0.8207 - categorical_accuracy: 0.7566 - top_3_accuracy: 0.9632 - val_loss: 1.1701 - val_categorical_accuracy: 0.6784 - val_top_3_accuracy: 0.8973\n",
      "Epoch 4/30\n",
      "891/892 [============================>.] - ETA: 0s - loss: 0.8084 - categorical_accuracy: 0.7643 - top_3_accuracy: 0.9603\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.77477\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "892/892 [==============================] - 585s 656ms/step - loss: 0.8081 - categorical_accuracy: 0.7643 - top_3_accuracy: 0.9603 - val_loss: 1.1157 - val_categorical_accuracy: 0.6775 - val_top_3_accuracy: 0.9297\n",
      "Epoch 5/30\n",
      "891/892 [============================>.] - ETA: 0s - loss: 0.7391 - categorical_accuracy: 0.7792 - top_3_accuracy: 0.9645\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.77477\n",
      "892/892 [==============================] - 577s 647ms/step - loss: 0.7412 - categorical_accuracy: 0.7791 - top_3_accuracy: 0.9646 - val_loss: 1.0499 - val_categorical_accuracy: 0.6694 - val_top_3_accuracy: 0.9207\n",
      "Epoch 6/30\n",
      "146/892 [===>..........................] - ETA: 8:24 - loss: 0.6769 - categorical_accuracy: 0.8068 - top_3_accuracy: 0.9726"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-ee7f3c67dc83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                    callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/finalpro/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath = \"combined_model_new.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "combined_new_history = combined_model_new.fit_generator(train_batches, steps_per_epoch=train_steps, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=valid_batches,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=30, verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.6949561887735702\n",
      "val_cat_acc: 0.77425206\n",
      "val_top_3_acc: 0.9428831\n"
     ]
    }
   ],
   "source": [
    "cnn.load_weights('combined_model_new.h5')\n",
    "\n",
    "val_loss, val_cat_acc, val_top_3_acc = \\\n",
    "cnn.evaluate_generator(test_batches, \n",
    "                        steps= len(validation_pr))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n",
    "print('val_top_3_acc:', val_top_3_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions, ytrue and ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103/1103 [==============================] - 65s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = cnn.predict_generator(test_batches, steps=len(validation_pr), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 5, 5, 5], dtype=int8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrue = pd.Categorical(validation_pr.dx).codes\n",
    "ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 5, 4, 5])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels = [\"akiec\", \"bcc\", \"bkl\", \"df\", \"mel\", \"nv\", \"vasc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.67      0.27      0.38        30\n",
      "         bcc       1.00      0.17      0.29        35\n",
      "         bkl       0.44      0.17      0.25        88\n",
      "          df       0.55      0.75      0.63         8\n",
      "         mel       0.15      0.70      0.25        46\n",
      "          nv       0.96      0.88      0.92       883\n",
      "        vasc       0.39      0.69      0.50        13\n",
      "\n",
      "    accuracy                           0.77      1103\n",
      "   macro avg       0.59      0.52      0.46      1103\n",
      "weighted avg       0.87      0.77      0.80      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(ytrue, y_pred, target_names=plot_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,   0,   3,   1,  16,   1,   1],\n",
       "       [  0,   6,   5,   0,  18,   4,   2],\n",
       "       [  3,   0,  15,   0,  55,  13,   2],\n",
       "       [  0,   0,   0,   6,   1,   1,   0],\n",
       "       [  1,   0,   3,   1,  32,   9,   0],\n",
       "       [  0,   0,   8,   3,  85, 778,   9],\n",
       "       [  0,   0,   0,   0,   2,   2,   9]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytrue, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(palette= \"Set2\", style= 'darkgrid')\n",
    "sns.set_context(\"notebook\",font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_top3_acc = history.history['top_3_accuracy']\n",
    "val_top3_acc = history.history['val_top_3_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(epochs, acc, label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "\n",
    "plt.plot(epochs, train_top3_acc, label='Training top3 acc')\n",
    "plt.plot(epochs, val_top3_acc, label='Validation top3 acc')\n",
    "plt.title('Training and validation top3 accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
