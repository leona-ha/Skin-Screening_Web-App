{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow.metrics\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, shutil, random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_pickle(\"./meta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"/Users/leona/PythonWork/Github_Projects/Final_Pro/data/ISIC2018_Task3_Training_Input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = len(train_data)\n",
    "num_val_samples = len(val_data)\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "image_size = 224\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning with pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38890 images belonging to 7 classes.\n",
      "Found 1103 images belonging to 7 classes.\n",
      "Found 1103 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= tensorflow.keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "train_batches = datagen.flow_from_directory(train_dir,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=train_batch_size)\n",
    "\n",
    "valid_batches = datagen.flow_from_directory(validation_dir,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=val_batch_size)\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "test_batches = datagen.flow_from_directory(validation_dir,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to choose how many layers we actually want to be trained.\n",
    "\n",
    "# Here we are freezing the weights of all layers except the\n",
    "# last 23 layers in the new model.\n",
    "# The last 23 layers of the model will be trained.\n",
    "\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge CNN output with demographic data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load demographic features for all images (augmented images included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnose = list(meta['dx'].unique())\n",
    "train_dir = \"/Users/leona/PythonWork/Github_Projects/Final_Pro/data/ISIC2018_Task3_Training_Input/train/\"\n",
    "validation_dir = \"/Users/leona/PythonWork/Github_Projects/Final_Pro/data/ISIC2018_Task3_Training_Input/validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagelist(classes,path):\n",
    "    img_list = []\n",
    "    for c in classes:\n",
    "        img_list.append(os.listdir(path + c))\n",
    "    img_list = [item for sublist in img_list for item in sublist]\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = get_imagelist(diagnose,train_dir)\n",
    "val_list = get_imagelist(diagnose,validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = list(meta.image_id)\n",
    "meta['img_nr'] = [image[5:] for image in meta.image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create helper function to extract pure image_id's\n",
    "def extract_id(x):\n",
    "        \n",
    "    if \"ISIC\" in x:\n",
    "        return x[5:12]\n",
    "    else:\n",
    "        return  x[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_img = pd.DataFrame(aug_list, columns=['aug_id'])\n",
    "aug_img['img_nr'] = aug_img['aug_id'].apply(extract_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img = pd.DataFrame(val_list, columns=['aug_id'])\n",
    "val_img['img_nr'] = val_img['aug_id'].apply(extract_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_train = pd.merge(aug_img, meta, how='inner', on=\"img_nr\", left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_test = pd.merge(val_img, meta, how='inner', on=\"img_nr\", left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False,\n",
    "         validate=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete_train.to_pickle(\"./aug_train.pkl\")\n",
    "#complete_test.to_pickle(\"./aug_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values, Min-Max-Scale and binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dem(train,test):\n",
    "\n",
    "\n",
    "    #replace missing age values by median\n",
    "    train['age'] = train['age'].fillna(train['age'].median())\n",
    "    test['age'] = test['age'].fillna(train['age'].median())\n",
    "    \n",
    "    # performin min-max scaling each continuous feature column to\n",
    "    # the range [0, 1]\n",
    "    cs = MinMaxScaler()\n",
    "    train[\"age\"] = cs.fit_transform(train[\"age\"].values.reshape(-1,1))\n",
    "    test[\"age\"] = cs.transform(test[\"age\"].values.reshape(-1,1))\n",
    " \n",
    "    train['sex'].replace(\"unknown\",train['sex'].value_counts().index[0], inplace=True)\n",
    "    train[\"sex\"] = np.where(train['sex']==\"female\",1,0)\n",
    "    \n",
    "    test['sex'].replace(\"unknown\",train['sex'].value_counts().index[0], inplace=True)\n",
    "    test[\"sex\"] = np.where(test['sex']==\"female\",1,0)\n",
    "    \n",
    "    # return the concatenated training and testing data\n",
    "    return (train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
